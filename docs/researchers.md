---
layout: default
title: Top Researchers
nav_order: 7
---
# Top Researchers in LM4SE
{: .no_toc }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

This page tracks the top researchers in language models for software engineering (LM4SE) over the past decade based on their publication record at top SE conferences. We analyzed all papers from ICSE, ASE, FSE, and ISSTA since 2012 to compile a list of prolific authors advancing the state-of-the-art in LM4SE.

### [Hongyu Zhang](https://www.semanticscholar.org/author/46702864)
- [Log-based Anomaly Detection Without Log Parsing](https://doi.org/10.1109/ASE51524.2021.9678773), ASE 2021
- [Log Parsing: How Far Can ChatGPT Go?](https://doi.org/10.1109/ASE56229.2023.00206), ASE 2023
- [Deep API learning](https://doi.org/10.1145/2950290.2950334), FSE 2016
- [Predicting Node failure in cloud service systems](https://doi.org/10.1145/3236024.3236060), FSE 2018
- [Robust log-based anomaly detection on unstable log data](https://doi.org/10.1145/3338906.3338931), FSE 2019
- [No more fine-tuning? an experimental evaluation of prompt tuning in code intelligence](https://doi.org/10.1145/3540250.3549113), FSE 2022
- [Diet code is healthy: simplifying programs for pre-trained models of code](https://doi.org/10.1145/3540250.3549094), FSE 2022
- [You see what I want you to see: poisoning vulnerabilities in neural code search](https://doi.org/10.1145/3540250.3549153), FSE 2022
- [A Novel Neural Source Code Representation Based on Abstract Syntax Tree](https://doi.org/10.1109/ICSE.2019.00086), ICSE 2019
- [Retrieval-based Neural Source Code Summarization](https://doi.org/10.1145/3377811.3380383), ICSE 2020
- [Cross-Domain Deep Code Search with Meta Learning](https://doi.org/10.1145/3510003.3510125), ICSE 2022
- [Improving Fault Localization and Program Repair with Deep Semantic Features and Transferred Knowledge](https://doi.org/10.1145/3510003.3510147), ICSE 2022
- [On the Evaluation of Neural Code Summarization](https://doi.org/10.1145/3510003.3510060), ICSE 2021
- [What Do They Capture? - A Structural Analysis of Pre-Trained Language Models for Source Code](https://doi.org/10.1145/3510003.3510050), ICSE 2022
- [Where is Your App Frustrating Users?](https://doi.org/10.1145/3510003.3510189), ICSE 2022
- [Keeping Pace with Ever-Increasing Data: Towards Continual Learning of Code Intelligence Models](https://doi.org/10.1109/ICSE48619.2023.00015), ICSE 2023
- [Template-based Neural Program Repair](https://doi.org/10.1109/ICSE48619.2023.00127), ICSE 2023
- [CoCoSoDa: Effective Contrastive Learning for Code Search](https://doi.org/10.1109/ICSE48619.2023.00185), ICSE 2022
- [Towards Efficient Fine-Tuning of Pre-trained Code Models: An Experimental Study and Beyond](https://doi.org/10.1145/3597926.3598036), ISSTA 2023
- [Detecting Condition-Related Bugs with Control Flow Graph Neural Network](https://doi.org/10.1145/3597926.3598142), ISSTA 2023
