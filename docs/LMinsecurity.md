---
layout: default
title: LM in Security
nav_order: 8
---
# Language Models in Security
{: .no_toc }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---


## Papers


### 2015
- [Exploiting and Protecting Dynamic Code Generation](https://www.ndss-symposium.org/ndss2015/exploiting-and-protecting-dynamic-code-generation) NDSS 2015
- [Readactor: Practical Code Randomization Resilient to Memory Disclosure](https://ieeexplore.ieee.org/ielx7/7160813/7163005/07163059.pdf) OAKLAND 2015

### 2016
- [Harvesting Runtime Values in Android Applications That Feature Anti-Analysis Techniques](http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2017/09/harvesting-runtime-values-android-applications-feature-anti-analysis-techniques.pdf) NDSS 2016

### 2017
- [Automated Crowdturfing Attacks and Defenses in Online Review Systems](https://arxiv.org/pdf/1708.08151) CCS 2017
- [POSTER: Vulnerability Discovery with Function Representation Learning from Unlabeled Projects](https://doi.org/10.1145/3133956.3138840) CCS 2017
- [A4NT: Author Attribute Anonymity by Adversarial Training of Neural Machine Translation](https://www.usenix.org/conference/usenixsecurity18/presentation/shetty) USENIX 2017

### 2018
- [Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs](https://doi.org/10.14722/ndss.2019.23492) NDSS 2018
- [AI2: Safety and Robustness Certification of Neural Networks with Abstract Interpretation](https://ieeexplore.ieee.org/ielx7/8418581/8418583/08418593.pdf) OAKLAND 2018

### 2019
- [Analyzing Information Leakage of Updates to Natural Language Models](https://arxiv.org/pdf/1912.07942) CCS 2019
- [CodeAlchemist: Semantics-Aware Code Generation to Find Vulnerabilities in JavaScript Engines](https://www.ndss-symposium.org/ndss-paper/codealchemist-semantics-aware-code-generation-to-find-vulnerabilities-in-javascript-engines/) NDSS 2019
- [Updates-Leak: Data Set Inference and Reconstruction Attacks in Online Learning](https://www.usenix.org/conference/usenixsecurity20/presentation/salem) USENIX 2019

### 2020
- [Privacy Risks of General-Purpose Language Models](https://ieeexplore.ieee.org/ielx7/9144328/9152199/09152761.pdf) OAKLAND 2020
- [Adversarial Watermarking Transformer: Towards Tracing Text Provenance with Data Hiding](https://arxiv.org/pdf/2009.03015) OAKLAND 2020
- [TextShield: Robust Text Classification Based on Multimodal Embedding and Neural Machine Translation](https://www.usenix.org/conference/usenixsecurity20/presentation/li-jinfeng) USENIX 2020
- [Montage: A Neural Network Language Model-Guided JavaScript Engine Fuzzer](https://www.usenix.org/conference/usenixsecurity20/presentation/lee-suyoung) USENIX 2020

### 2021
- [Structured Leakage and Applications to Cryptographic Constant-Time and Cost](https://doi.org/10.1145/3460120.3484761) CCS 2021
- [Cert-RNN: Towards Certifying the Robustness of Recurrent Neural Networks](https://doi.org/10.1145/3460120.3484538) CCS 2021
- [Hidden Backdoors in Human-Centric Language Models](https://arxiv.org/pdf/2105.00164) CCS 2021
- [Backdoor Pre-trained Models Can Transfer to All](https://arxiv.org/pdf/2111.00197) CCS 2021
- [PalmTree: Learning an Assembly Language Model for Instruction Embedding](https://dl.acm.org/doi/pdf/10.1145/3460120.3484587) CCS 2021
- [Bolt-Dumbo Transformer: Asynchronous Consensus As Fast As the Pipelined BFT](https://doi.org/10.1145/3548606.3559346) CCS 2021
- [Get a Model! Model Hijacking Attack Against Machine Learning Models](https://doi.org/10.14722/ndss.2022.23064) NDSS 2021
- [SiRnn: A Math Library for Secure RNN Inference](https://arxiv.org/pdf/2105.04236) OAKLAND 2021
- [Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions](https://arxiv.org/pdf/2108.09293) OAKLAND 2021
- [Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures](https://arxiv.org/pdf/2112.05224) OAKLAND 2021
- [Examining Zero-Shot Vulnerability Repair with Large Language Models](https://arxiv.org/pdf/2112.02125) OAKLAND 2021
- [SmarTest: Effectively Hunting Vulnerable Transaction Sequences in Smart Contracts through Language Model-Guided Symbolic Execution](https://www.usenix.org/conference/usenixsecurity21/presentation/so) USENIX 2021
- [An Empirical Study of Training Self-Supervised Vision Transformers](https://arxiv.org/pdf/2104.02057) USENIX 2021

### 2022
- [Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models](https://doi.org/10.1145/3548606.3560683) CCS 2022
- [LoneNeuron: A Highly-Effective Feature-Domain Neural Trojan Using Invisible and Polymorphic Watermarks](https://dl.acm.org/doi/pdf/10.1145/3548606.3560678) CCS 2022
- [Poster  Towards Authorship Obfuscation with Language Models](https://doi.org/10.1145/3548606.3563512) CCS 2022
- [A Generic Methodology for the Modular Verification of Security Protocol Implementations](https://arxiv.org/pdf/2212.02626) CCS 2022
- [Interpretable Federated Transformer Log Learning for Cloud Threat Forensics](https://www.ndss-symposium.org/ndss-paper/auto-draft-236/) NDSS 2022
- [Reconstructing Training Data with Informed Adversaries](https://arxiv.org/pdf/2201.04845) OAKLAND 2022
- [Piccolo: Exposing Complex Backdoors in NLP Transformer Models](https://doi.org/10.1109/SP46214.2022.9833579) OAKLAND 2022
- [for Prediction City Region Re-Weighting](https://www.usenix.org/conference/usenixsecurity22/presentation/fang) USENIX 2022
- [Membership Inference Attacks and Defenses in Neural Network Pruning](https://www.usenix.org/conference/usenixsecurity22/presentation/yuan-xiaoyong) USENIX 2022
- [Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants](https://www.usenix.org/conference/usenixsecurity23/presentation/sandoval) USENIX 2022

### 2023
- [Transformer-based Model for Multi-tab Website Fingerprinting Attack](https://doi.org/10.1145/3576915.3623107) CCS 2023
- [Stealing the Decoding Algorithms of Language Models](https://arxiv.org/pdf/2303.04729) CCS 2023
- [Large Language Models for Code: Security Hardening and Adversarial Testing](https://arxiv.org/pdf/2302.05319) CCS 2023
- [Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks](https://doi.org/10.1145/3576915.3623120) CCS 2023
- [SalsaPicante: A Machine Learning Attack on LWE with Binary Secrets](https://arxiv.org/pdf/2303.04178) CCS 2023
- [DP-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass](https://arxiv.org/pdf/2309.06746) CCS 2023
- [Read Between the Lines: Detecting Tracking JavaScript with Bytecode Classification](https://doi.org/10.1145/3576915.3616637) CCS 2023
- [Poster: Boosting Adversarial Robustness by Adversarial Pre-training](https://doi.org/10.1145/3576915.3624370) CCS 2023
- [Demo: Certified Robustness on Toolformer](https://doi.org/10.1145/3576915.3624362) CCS 2023
- [BARS: Local Robustness Certification for Deep Learning based Traffic Analysis Systems](https://www.ndss-symposium.org/ndss-paper/bars-local-robustness-certification-for-deep-learning-based-traffic-analysis-systems/) NDSS 2023
- [Redeem Myself: Purifying Backdoors in Deep Learning Models using Self Attention Distillation](https://doi.org/10.1109/SP46215.2023.10179375) OAKLAND 2023
- [Robust Multi-tab Website Fingerprinting Attacks in the Wild](https://doi.org/10.1109/SP46215.2023.10179464) OAKLAND 2023
- [Improving Real-world Password Guessing Attacks via Bi-directional Transformers](https://www.usenix.org/conference/usenixsecurity23/presentation/xu-ming) USENIX 2023
- [CodexLeaks: Privacy Leaks from Code Generation Language Models in GitHub Copilot](https://www.usenix.org/conference/usenixsecurity23/presentation/niu) USENIX 2023
- [Two-in-One: A Model Hijacking Attack Against Text Generation Models](http://arxiv.org/pdf/2305.07406) USENIX 2023
- [PELICAN: Exploiting Backdoors of Naturally Trained Deep Learning Models In Binary Code Analysis](https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-zhuo-pelican) USENIX 2023
- [A Data-free Backdoor Injection Approach in Neural Networks](https://www.usenix.org/conference/usenixsecurity23/presentation/lv) USENIX 2023
- [Network Detection of Interactive SSH Impostors Using Deep Learning](https://www.usenix.org/conference/usenixsecurity23/presentation/piet) USENIX 2023


## Top Researchers in LLMSec

- [Shouling Ji](https://www.semanticscholar.org/author/2081160)
- [Jinfeng Li](https://www.semanticscholar.org/author/46275709)
- [Ting Wang](https://www.semanticscholar.org/author/2155389584)
- [Ahmed Salem](https://www.semanticscholar.org/author/66697271)
- [Michael Backes](https://www.semanticscholar.org/author/144588806)
- [Yang Zhang](https://www.semanticscholar.org/author/2145954003)
- [Mario Fritz](https://www.semanticscholar.org/author/1739548)
- [Hammond Pearce](https://www.semanticscholar.org/author/3437933)
- [Brendan Dolan-Gavitt](https://www.semanticscholar.org/author/1398683279)
- [R. Karri](https://www.semanticscholar.org/author/1707355)
- [Tianyu Du](https://www.semanticscholar.org/author/2056897605)
- [Lujia Shen](https://www.semanticscholar.org/author/1382593028)
- [Jie Shi](https://www.semanticscholar.org/author/2112364113)
- [Chengfang Fang](https://www.semanticscholar.org/author/3248634)
- [Jianwei Yin](https://www.semanticscholar.org/author/2111610043)
- [Martin T. Vechev](https://www.semanticscholar.org/author/1736447)
- [HyungSeok Han](https://www.semanticscholar.org/author/143935376)
- [Sang Kil Cha](https://www.semanticscholar.org/author/3695676)
- [Min Yang](https://www.semanticscholar.org/author/1492164677)
- [Baleegh Ahmad](https://www.semanticscholar.org/author/2124891963)
- [Benjamin Tan](https://www.semanticscholar.org/author/143645422)
- [Yingqi Liu](https://www.semanticscholar.org/author/2007064152)
- [Guangyu Shen](https://www.semanticscholar.org/author/2052467415)
- [Guanhong Tao](https://www.semanticscholar.org/author/48927894)
- [Shengwei An](https://www.semanticscholar.org/author/2072528961)