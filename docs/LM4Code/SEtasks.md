---
layout: default
title: SE Tasks
parent: LM4Code_LM4SE
---

# SE Tasks
{: .no_toc }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

## Code Completion
- A systematic evaluation of large language models of code, 2022;
- An empirical study on the usage of transformer models for code completion, 2021, [link](https://ieeexplore.ieee.org/document/9616462/)
- Automatic detection and analysis of technical debts in peer-review documentation of r packages, 2022, [link](http://arxiv.org/abs/2201.04241)
- CCTest: Testing and repairing code completion systems, 2023, [link](http://arxiv.org/abs/2208.08289)
- CodeFill: Multi-token code completion by jointly learning from structure and naming sequences, 2022, [link](https://dl.acm.org/doi/10.1145/3510003.3510172)
- Evaluating and improving transformers pre-trained on ASTs for code completion, 2023, [link](https://ieeexplore.ieee.org/document/10123540/)
- Examining zero-shot vulnerability repair with large language models, 2022, [link](http://arxiv.org/abs/2112.02125)
- From Copilot to Pilot: Towards AI supported software development, 2023, [link](http://arxiv.org/abs/2303.04142)
- Making the most of small Software Engineering datasets with modern machine learning, 2022, [link](https://ieeexplore.ieee.org/document/9653849/)
- Multi-task learning based pre-trained language model for code completion, 2020, [link](https://dl.acm.org/doi/10.1145/3324884.3416591)
- Natural Language Generation and Understanding of Big Code for AI-Assisted Programming: A Review, 2023;
- Piloting Copilot and Codex: Hot temperature, cold prompts, or black magic?, 2023, [link](http://arxiv.org/abs/2210.14699)
- RepoBench: Benchmarking repository-level code auto-completion systems, 2023, [link](http://arxiv.org/abs/2306.03091)
- Toward less hidden cost of code completion with acceptance and ranking models, 2021, [link](http://arxiv.org/abs/2106.13928)


## Code comment generation
- An Empirical Study on Code Comment Completion, 2021, [link](http://arxiv.org/abs/2107.10544)
- Large Language Models are Few-shot Summarizers: Multi-intent Comment Generation via In-context Learning, 2023, [link](http://arxiv.org/abs/2304.11384)


## Code search
- Cross-Modal Contrastive Learning for Code Search, 2022, [link](https://ieeexplore.ieee.org/document/9978195/)
- Do Pre-trained Language Models Indeed Understand Software Engineering Tasks?, 2022, [link](http://arxiv.org/abs/2211.10623)
- Generation-Augmented Query Expansion for Code Retrieval, 2022, [link](http://arxiv.org/abs/2212.10692)
- On Contrastive Learning of Semantic Similarity for Code-to-Code Search, 2023, [link](http://arxiv.org/abs/2305.03843)
- On the Effectiveness of Transfer Learning for Code Search, 2023, [link](https://ieeexplore.ieee.org/document/9835142/)

## Code summarization
- Assemble Foundation Models for Automatic Code Summarization, 2022, [link](http://arxiv.org/abs/2201.05222)
- Constructing Effective In-Context Demonstration for Code Intelligence Tasks: An Empirical Study, 2023, [link](http://arxiv.org/abs/2304.07575)
- Exploring Distributional Shifts in Large Language Models for Code Analysis, 2023, [link](http://arxiv.org/abs/2303.09128)
- Extending Source Code Pre-trained Language Models to Summarise Decompiled Binaries, 2023, [link](http://arxiv.org/abs/2301.01701)
- Improving Few-shot Prompts with Relevant Static Analysis Products, 2023, [link](http://arxiv.org/abs/2304.06815)
- Multilingual Adapter-based Knowledge Aggregation on Code Summarization for Low-Resource Languages, 2023
- On the Transferability of Pre-trained Language Models for Low-Resource Programming Languages, 2022, [link](https://dl.acm.org/doi/10.1145/3524610.3527917)
- Studying the Usage of Text-to-Text Transfer Transformer to Support Code-Related Tasks, 2021, [link](https://ieeexplore.ieee.org/document/9401982/)
- Using Transfer Learning for Code-Related Tasks, 2023, [link](https://ieeexplore.ieee.org/document/9797060/)


## Program synthesis
- Evaluating ChatGPT and GPT-4 for Visual Programming, 2023
- Exploring the Robustness of Large Language Models for Solving Programming Problems, 2023
- Jigsaw: Large Language Models Meet Program Synthesis, 2022, [link](https://dl.acm.org/doi/10.1145/3510003.3510203)
- Less is More: Summary of Long Instructions is Better for Program Synthesis, 2022
- Natural Language Commanding via Program Synthesis, 2023, [link](http://arxiv.org/abs/2306.03460)






# Program Repair
- Toward less hidden cost of code completion with acceptance and ranking models, 2021, [link](http://arxiv.org/abs/2106.13928)
- A Chain of AI-based Solutions for Resolving FQNs and Fixing Syntax Errors in Partial Code, 2023
- a new era in software security: towards self-healing software via large language models and formal verification, 2023, [link](http://arxiv.org/abs/2305.14752)
- a prompt pattern catalog to enhance prompt engineering with chatgpt, 2023, [link](http://arxiv.org/abs/2302.11382)
- a study on prompt design, advantages and limitations of chatgpt for deep learning program repair, 2023, [link](http://arxiv.org/abs/2304.08191)
- Addressing Compiler Errors: Stack Overflow or Large Language Models?, 2023
- an analysis of the automatic bug fixing performance of chatgpt, 2023, [link](http://arxiv.org/abs/2301.08653)
- automated repair of programs from large language models, 2023, [link](http://arxiv.org/abs/2205.10583)
- boosting automated patch correctness prediction via pre-trained language model, 2023, [link](http://arxiv.org/abs/2301.12453)
- circle: continual repair across programming languages, 2022, [link](https://dl.acm.org/doi/10.1145/3533767.3534219)
- constructing effective in-context demonstration for code intelligence tasks: an empirical study, 2023, [link](http://arxiv.org/abs/2304.07575)
- conversational automated program repair, 2023, [link](http://arxiv.org/abs/2301.13246)
- Enhancing Automated Program Repair through Fine-tuning and Prompt Engineering, 2023
- evaluating representation learning of code changes for predicting patch correctness in program repair, 2020, [link](https://dl.acm.org/doi/10.1145/3324884.3416532)
- how effective are neural networks for fixing security vulnerabilities, 2023, [link](http://arxiv.org/abs/2305.18607)
- inferfix: end-to-end program repair with llms, 2023, [link](http://arxiv.org/abs/2303.07263)
- invalidator: automated patch correctness assessment via semantic and syntactic reasoning, 2023, [link](http://arxiv.org/abs/2301.01113)
- is chatgpt the ultimate programming assistant -- how far is it?, 2023, [link](http://arxiv.org/abs/2304.11938)
- keep the conversation going: fixing 162 out of 337 bugs for $0.42 each using chatgpt, 2023, [link](http://arxiv.org/abs/2304.00385)
- neural program repair with program dependence analysis and effective filter mechanism, 2023, [link](http://arxiv.org/abs/2305.09315)
- practical program repair in the era of large pre-trained language models, 2022, [link](http://arxiv.org/abs/2210.14179)
- the best of both worlds: combining learned embeddings with engineered features for accurate prediction of correct patches, 2023, [link](https://dl.acm.org/doi/10.1145/3576039)
- towards javascript program repair with generative pre-trained transformer (gpt-2), 2022, [link](https://dl.acm.org/doi/10.1145/3524459.3527350)
- using transfer learning for code-related tasks, 2023

## Code clone detection
- an exploratory study on code attention in bert, 2022, [link](https://dl.acm.org/doi/10.1145/3524610.3527921)
- Towards Understanding the Capability of Large Language Models on Code Clone Detection: A Survey, 2023
- Utilization of Pre-trained Language Model for Adapter-based Knowledge Transfer in Software Engineering, 2023

## Bug report analysis
- fast changeset-based bug localization with bert, 2022, [link](https://dl.acm.org/doi/10.1145/3510003.3510042)
- Few-shot learning for sentence pair classification and its applications in software engineering, 2023
- large language models are few-shot testers: exploring llm-based general bug reproduction, 2022, [link](http://arxiv.org/abs/2209.11515)

## Code Review
- A Multi-Step Learning Approach to Assist Code Review, 2023
- aspect-based api review classification: how far can pre-trained transformer model go?, 2022, [link](http://arxiv.org/abs/2201.11327)
- auger: automatically generating review comments with pre-training models, 2022, [link](https://dl.acm.org/doi/10.1145/3540250.3549099)
- Automated Summarization of Stack Overflow Posts, 2023, [link](https://arxiv.org/abs/2305.16680)
- coditt5: pretraining for source code and natural language editing, 2022, [link](https://dl.acm.org/doi/10.1145/3551349.3556955)
- using pre-trained models to boost code review automation, 2022, [link](https://dl.acm.org/doi/10.1145/3510003.3510621)

## Test generation
- adaptive test generation using a large language model, 2023, [link](http://arxiv.org/abs/2302.06527)
- algo: synthesizing algorithmic programs with generated oracle verifiers, 2023, [link](http://arxiv.org/abs/2305.14591)
- Can Large Language Models Write Good Property-Based Tests?, 2023
- chatunitest: a chatgpt-based automated unit test generation tool, 2023, [link](http://arxiv.org/abs/2305.04764)
- exploring the effectiveness of large language models in generating unit tests, 2023, [link](http://arxiv.org/abs/2305.00418)
- no more manual tests? evaluating and improving chatgpt for unit test generation, 2023, [link](http://arxiv.org/abs/2305.04207)

## Vulnerability detection
- csgvd: a deep learning approach combining sequence and graph embedding for source code vulnerability detection, 2023, [link](https://linkinghub.elsevier.com/retrieve/pii/S0164121223000183)
- Detecting Phishing Sites Using ChatGPT, 2023
- diversevul: a new vulnerable source code dataset for deep learning-based vulnerability detection, 2023, [link](http://arxiv.org/abs/2304.00409)
- low-level source code vulnerability detection using advanced BERT language model, 2022, [link](https://caiac.pubpub.org/pub/gdhb8oq4)
- transformer-based language models for software vulnerability detection, 2022, [link](https://dl.acm.org/doi/10.1145/3564625.3567985)
- transformer-based vulnerability detection in code at edittime: zero-shot, few-shot, or fine-tuning?, 2023, [link](http://arxiv.org/abs/2306.01754)
- When GPT Meets Program Analysis: Towards Intelligent Detection of Smart Contract Logic Vulnerabilities in GPTScan, 2023


## Code Generation
- A Lightweight Framework for High-Quality Code Generation, 2023
- A Syntax-Guided Multi-Task Learning Approach for Turducken-Style Code Generation, 2023, [link](http://arxiv.org/abs/2303.05061)
- A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets, 2023
- AI for Low-Code for AI, 2023, [link](http://arxiv.org/abs/2305.20015)
- Aligning Offline Metrics and Human Judgments of Value of AI-Pair Programmers, 2022, [link](http://arxiv.org/abs/2210.16494)
- An Extensive Study on Pre-trained Models for Program Understanding and Generation, 2022, [link](https://dl.acm.org/doi/10.1145/3533767.3534390)
- ANPL: Compiling Natural Programs with Interactive Decomposition, 2023, [link](http://arxiv.org/abs/2305.18498)
- Capturing Failures of Large Language Models via Human Cognitive Biases, 2022, [link](http://arxiv.org/abs/2202.12299)
- CERT: Continual Pre-training on Sketches for Library-Oriented Code Generation, 2022, [link](https://www.ijcai.org/proceedings/2022/329)
- ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation, 2023
- Code Generation Tools (Almost) for Free? A Study of Few-shot, Pre-trained Language Models on Code, 2022, [link](http://arxiv.org/abs/2206.01335)
- CodeCompose: A Large-scale Industrial Deployment of AI-assisted Code Authoring, 2023, [link](http://arxiv.org/abs/2305.12050)
- CodeGeex: A Pre-trained Model for Code Generation with Multilingual Evaluations on Humaneval-X, 2023, [link](http://arxiv.org/abs/2303.17568)
- CodeIE: Large Code Generation Models Are Better Few-shot Information Extractors, 2023, [link](http://arxiv.org/abs/2305.05711)
- CodeEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models, 2023, [link](http://arxiv.org/abs/2302.00288)
- Comparing Software Developers with ChatGPT: An Empirical Investigation, 2023, [link](http://arxiv.org/abs/2305.11837)
- Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based Large Language Models, 2023
- Demystifying GPT Self-Repair for Code Generation, 2023
- DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation, 2022, [link](http://arxiv.org/abs/2211.11501)
- Enabling Programming Thinking in Large Language Models Toward Code Generation, 2023
- Evaluating AIGC Detectors on Code Content, 2023, [link](http://arxiv.org/abs/2304.05193)
- Evaluating Large Language Models Trained on Code, 2021, [link](http://arxiv.org/abs/2107.03374)
- Evaluating the Code Quality of AI-Assisted Code Generation Tools: An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and ChatGPT, 2023, [link](http://arxiv.org/abs/2304.10778)
- Extending the Frontier of ChatGPT: Code Generation and Debugging, 2023
- GRACE: Generation using Associated Code Edits, 2023, [link](http://arxiv.org/abs/2305.14129)
- Improving ChatGPT Prompt for Code Generation, 2023, [link](http://arxiv.org/abs/2305.08360)
- Improving Code Generation by Training with Natural Language Feedback, 2023, [link](http://arxiv.org/abs/2303.16749)
- Interactive Code Generation via Test-Driven User-Intent Formalization, 2022, [link](http://arxiv.org/abs/2208.05950)
- Is Model Attention Aligned with Human Attention? An Empirical Study on Large Language Models for Code Generation, 2023, [link](http://arxiv.org/abs/2306.01220)
- Is this Snippet Written by ChatGPT? An Empirical Study with, 2023
