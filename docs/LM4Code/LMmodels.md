---
layout: default
title: Large Language Models
parent: LM4Code/LM4SE
nav_order: 1
---
# Large Language Models for Code
{: .no_toc }

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}

---

Language models have shown impressive capabilities for various natural language processing and software engineering tasks. This page catalogs key details and papers for influential LLMs that have been applied to software tasks.

![](../figures/LLMs.png)

### GPT-1
- Release Date: 2018-06
- Institute: OpenAI
- Paper: [Improving Language Understanding by Generative Pre-Training](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf)

### GPT-2
- Release Date: 2019-02
- Institute: OpenAI
- Paper: [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

### GPT-3
- Release Date: 2020-05
- Institute: OpenAI
- Paper: [Language models are few-shot learners](https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)

### Codex
- Release Date: 2021-08
- Institute: OpenAI
- Paper: [Evaluating Large Language Models Trained on Code](https://arxiv.org/pdf/2107.03374.pdf)

### GPT-NeoX
- Release Date: 2022-04
- Access: [ckpt](https://github.com/EleutherAI/gpt-neox)
- Paper: [GPT-NeoX-20B: An Open-Source Autoregressive Language Model](https://arxiv.org/pdf/2204.06745.pdf)

### GPT-Neo
- Release Date: 2021-03
- Source: [Github](https://github.com/EleutherAI/gpt-neo)

### CodeGen
- Release Date: 2022/03
- Paper: [CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis](https://arxiv.org/abs/2203.13474)

### InstructGPT
- Release Date: 2022/01
- Paper: [Training language models to follow instructions with human feedback](http://arxiv.org/abs/2203.02155v1)

### CodeGeeX
- Title: CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X
- Year: 2023
- Paper: [Link](https://arxiv.org/abs/2303.17568)

### GPT-J
- Release Date: 2023/06
- Access: [GPT-J-6B](https://github.com/kingoflolz/mesh-transformer-jax/#gpt-j-6b), [GPT4All-J](https://github.com/nomic-ai/gpt4all#raw-model)
- Paper: [GPT-J-6B: 6B JAX-Based Transformer](https://arankomatsuzaki.wordpress.com/2021/06/04/gpt-j/)

### LLaMA
- Release Date: 2023-02
- Institute: Meta
- Paper: [LLaMA: Open and Efficient Foundation Language Models](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)

### ChatGPT
- Release Date: 2022-11
- Access: [demo](https://openai.com/blog/chatgpt/), [api](https://share.hsforms.com/1u4goaXwDRKC9-x9IvKno0A4sk30)
- Origin: [Blog](https://openai.com/blog/chatgpt/)

### StableLM-Alpha
- Release Date: 2023/04
- Access: [StableLM-Alpha](https://github.com/Stability-AI/StableLM#stablelm-alpha)
- Paper: [Stability AI Launches the First of its StableLM Suite of Language Models](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)


### InCoder
- Paper: "InCoder: A Generative Model for Code Infilling and Synthesis"
- Authors: Daniel Fried et al.
- Release Date: 2023   
- Paper: [Link](http://arxiv.org/abs/2204.05999)

### GPT-4
- Release Date: 2023-03
- Institute: OpenAI
- Paper: [GPT-4 Technical Report](https://openai.com/research/gpt-4)

### WizardCoder
- Access: [WizardLM|WizardCoder](https://github.com/nlpxucan/WizardLM)

### PanGu-Coder
- Part of: PanGu-α
- Release Date: 2020
- Paper: ["PanGu-α: Large-scale Autoregressive Pretrained Chinese Language Models with Auto-parallel Computation"](https://arxiv.org/abs/2010.11934)

### OPT
- Release Date: 2022-05
- Access: [api](https://opt.alpa.ai), [ckpt](https://github.com/facebookresearch/metaseq/tree/main/projects/OPT)
- Paper: [OPT: Open Pre-trained Transformer Language Models](https://arxiv.org/pdf/2205.01068.pdf)

### StarCoder
- Release Date: 2023/05
- Access: [starcoder](https://huggingface.co/bigcode/starcoder)
- Papers: [StarCoder: A State-of-the-Art LLM for Code](https://huggingface.co/blog/starcoder), [StarCoder: May the source be with you!](https://drive.google.com/file/d/1cN-b9GnWtHzQRoE7M7gAEyivY0kl4BYs/view)

### SantaCoder
- Release Date: 2023/01
- Access: [santacoder](https://huggingface.co/bigcode/santacoder)
- Paper: [SantaCoder: don't reach for the stars!](https://arxiv.org/abs/2301.03988)

### PaLM
- Release Date: 2022-04
- Institute: Google
- Paper: [PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/pdf/2204.02311.pdf)

### Vicuna
- Release Date: 2023/03
- Blog: [Link](https://lmsys.org/blog/2023-03-30-vicuna/)

### Flan-UL2
- Release Date: 2023-03
- Institute: Google
- Blog: [Flan-UL2 Blog](https://www.yitay.net/blog/flan-ul2-20b)

### CPM-Bee
- Release Date: 2022-10
- Institute: Baidu
- Paper: [CPM: A Large-scale Generative Chinese Pre-trained Language Model](https://arxiv.org/pdf/2012.00413.pdf)

### MT-NLG
- Release Date: 2022-01
- Institute: Microsoft
- Paper: [Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model](https://arxiv.org/pdf/2201.11990.pdf)

### GLM
- Release Date: 2022-10
- Institute: Tsinghua University
- Paper: [GLM-130B: AN OPEN BILINGUAL PRE-TRAINED MODEL](https://arxiv.org/pdf/2210.02414.pdf)

### YaLM
- Release Date: 2022-06
- Institute: Yandex
- Blog: [YaLM Blog](https://medium.yandex/yandex-publishes-yalm-100b-its-the-largest-gpt-like-neural-network-in-open-source-d1df53d0e9a6)

### Alpaca
- Release Date: 2023-03
- Institute: Stanford University
- Access: [Alpaca GitHub](https://github.com/tatsu-lab/stanford_alpaca)

### RWKV-4
- Release Date: 2022-09
- Institute: Independent (BlinkDL)
- Access: [RWKV-4 GitHub](https://github.com/BlinkDL/RWKV-LM)

### Sparrow
- Release Date: 2022-09
- Institute: DeepMind
- Paper: [Improving alignment of dialogue agents via targeted human judgements](https://arxiv.org/pdf/2209.14375.pdf)

### Falcon
- Release Date: 2023-05
- Institute: Technology Innovation Institute (TII)
- Access: [Falcon Homepage](https://falconllm.tii.ae)

### Code Llama
- Release Date: 2023
- Institute: Meta (Facebook)
- Paper: [Code Llama: Open Foundation Models for Code](https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/)

### RedPajama-INCITE
- Release Date: Not specified
- Blog: [RedPajama-INCITE Blog](https://www.together.xyz/blog/redpajama-models-v1)

### DeciCoder-1B
- Release Date: 2023-08
- Institute: Deci AI
- Blog: [DeciCoder Blog](https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/)

### OpenLLaMA
- Release Date: 2023-05
- Institute: Not specified
- Access: [OpenLLaMA Access](https://huggingface.co/Salesforce/codegen25-7b-multi/blob/main/README.md)


### CodeGPT
- Release Date: 2021
- Paper: [CodeXGLUE: A Machine Learning Benchmark Dataset for Code Understanding and Generation](https://arxiv.org/pdf/2102.04664.pdf)


## Encoder-only Models
### BERT
- Release Date: 2018-10
- Institute: Google
- Paper: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://aclanthology.org/N19-1423.pdf)

### ALBERT
- Release Date: 2019
- Paper: [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942)

### RoBERTa
- Release Date: 2019
- Paper: [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)

### CodeBERT
- Release Date: 2020-04
- Institute: Microsoft
- Paper: [CodeBERT: A Pre-Trained Model for Programming and Natural Languages](https://arxiv.org/abs/2002.08155)

### GraphCodeBERT
- Release Date: 2022/03
- Access: [GraphCodeBERT](https://huggingface.co/microsoft/graphcodebert-base)
- Paper: [GraphCodeBERT: Pre-training Code Representations with Data Flow
](https://arxiv.org/abs/2009.08366)

## Encoder-decoder Models

### AlphaCode
- Release Date: 2022/02

### T5
- Release Date: 2019
- Paper: [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683)
- Checkpoint: [Link](https://huggingface.co/t5-11b)

### CodeT5
- Release Date: 2021
- Access: [CodeT5](https://huggingface.co/salesforce/codet5-small)
- Paper: [CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation](https://arxiv.org/abs/2109.00859)


### CodeT5+
- Release Date: 2023/05
- Access: [CodeT5+](https://github.com/salesforce/CodeT5/tree/main/CodeT5+)
- Paper: [CodeT5+: Open Code Large Language Models for Code Understanding and Generation](https://arxiv.org/abs/2305.07922)


### UnixCoder
- Release Date: 2022
- Access: [UniXcoder on Hugging Face](https://huggingface.co/microsoft/unixcoder-base)
- Paper: [UniXcoder: Unified Cross-Modal Pre-training for Code Representation
](https://arxiv.org/abs/2203.03850)

### PLBART
- Release Date: 2021
- Paper: [Unified Pre-training for Program Understanding and Generation
](https://arxiv.org/abs/2103.06333)


### CodeReviewer
- Release Date: 2022
- Access: [CodeReviewer](https://huggingface.co/microsoft/codereviewer)
- Paper: [Automating Code Review Activities by Large-Scale Pre-training](https://arxiv.org/abs/2203.09095)
